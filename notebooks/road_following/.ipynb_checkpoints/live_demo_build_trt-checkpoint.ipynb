{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following - Build TensorRT model for live demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will optimize the model we trained using TensorRT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This script is only for the models trained with \"train_model_PC.ipynb\". If the model is trained with \"train_model.ipynb\", you should use live_demo_build_trt_o.ipynb.\n",
    "2. Before executing this script, you should copy the whole directory and the trained model files saved inside it to \"Home/model_repo\", where HOME is the home directory of your Jetson Nano (here, we assume HOME=/home/cuterbot). The trained model files is saved in the directory variable \"DIR_RC_MODEL_REPO\" you set in \"train_model_PC.ipynb\", which should be in the PC used for training.\n",
    "3. The pytorch model will be uploaded after you selected the model from the selection widget in the cell below.\n",
    "> Note: Please make sure the file has been uploaded fully from the log console of jupyter lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code below to initialize the PyTorch model. This should look very familiar from the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jetbot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjetbot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_selection\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwidgets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jetbot'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from jetbot.utils import model_selection\n",
    "import os \n",
    "import ipywidgets.widgets as widgets\n",
    "from ipywidgets.widgets import Box, HBox, VBox, Layout, Label, Output\n",
    "import traitlets\n",
    "\n",
    "# The path of trt models is 'MODEL_REPO_DIR_DOCKER' which is set in /jetbot/utils/model_selection.py,\n",
    "# which may be modified if you change the file path of trt models, 'MODEL_REPO_DIR_DOCKER' or dir_model_repo.\n",
    "\n",
    "dir_model_repo = os.environ['MODEL_REPO_DIR_DOCKER']\n",
    "print(dir_model_repo)\n",
    "\n",
    "# pth_ms = model_selection(core_library = \"Pytorch\")  # if 'MODEL_REPO_DIR_DOCKER' is used.\n",
    "pth_ms = model_selection(core_library = \"Pytorch\", dir_model_repo=dir_model_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_ms.model_function = \"classifier\"\n",
    "\n",
    "model_type_widget = widgets.Select(options=pth_ms.model_type_list, value=pth_ms.model_type_list[0],\n",
    "                                      description='Model Type:')\n",
    "traitlets.dlink((pth_ms, 'model_type_list'), (model_type_widget, 'options'))\n",
    "traitlets.dlink((model_type_widget, 'value'), (pth_ms, 'model_type'))\n",
    "\n",
    "model_path_widget = widgets.Select(options=pth_ms.model_path_list, description='Model Path:',\n",
    "                                      layout=Layout(width='65%'))\n",
    "traitlets.dlink((pth_ms, 'model_path_list'), (model_path_widget, 'options'))\n",
    "traitlets.dlink((model_path_widget, 'value'), (pth_ms, 'model_path'))\n",
    "\n",
    "path_preprocess = pth_ms.preprocess_path  # the preprocess for torch model is used for trt model\n",
    "print('preprocess path:', path_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the pytoch model and the trained weights from the model_path (e.g.``best_steering_model_xy_<<pth_model_name>>.pth``) file that you uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Output(layout={'border': '2px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@out.capture()\n",
    "device = torch.device('cuda')\n",
    "def load_trained_model(model_path, pth_model_name):\n",
    "    from jetbot.utils.model_selection import load_tune_pth_model\n",
    "    # model_path = model_path_widget.value\n",
    "    # pth_model_name = model_path_widget.value.split('/')[-1].split('.')[0].split('_', 4)[-1]\n",
    "    print(\"start load trained model -- \\n model name : \", pth_model_name, '\\n model path: ', model_path)\n",
    "\n",
    "    model, model_type, preprocess = load_tune_pth_model(pth_model_name=pth_model_name, pretrained=False)  \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model = model.to(device).eval().half()\n",
    "    # model = model.cuda().eval().half()\n",
    "    # Currently, the model weights are located on the CPU memory execute the code below to transfer to the GPU device. \n",
    "    # device = torch.device('cuda')\n",
    "    \n",
    "    return model_type, model, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT conversion:\n",
    "\n",
    "1. If you are running with docker container, you may not need to do the following installation.\n",
    "> Note: If your setup does not have `torch2trt` installed, you need to first install `torch2trt` by executing the following in the console.\n",
    "```bash\n",
    "    cd $HOME\n",
    "    git clone https://github.com/NVIDIA-AI-IOT/torch2trt\n",
    "    cd torch2trt\n",
    "    sudo python3 setup.py install\n",
    "```\n",
    "> Convert and optimize the model using torch2trt for faster inference with TensorRT. Please see the [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt) readme for more details.\n",
    "> This optimization process can take a couple minutes to complete.\n",
    "\n",
    "2. After finishing TensorRT engine conversion, the created TensorRT model engines will be stored in same directory you specified to store the step 2 above (\"Home/model_repo/road_following\"), and the mata data file 'trt_model_tbl.csv' will be updated in directory \"Home/model_repo\".\n",
    "3. Then, you can excute the \"live_demo_light_trt.ipynb\" to simulate the road following function with the converted TensorRT engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@out.capture()\n",
    "def trt_conversion(pth_model_name, model, preprocess_tmp):\n",
    "    from torch2trt import torch2trt\n",
    "    from jetbot.utils import tv_classifier_preprocess\n",
    "    \n",
    "    print(\"start building TRT model -- \")\n",
    "    \n",
    "    if preprocess_tmp is None:  # load pre-stored preprocess module of the trained model\n",
    "        preprocess = tv_classifier_preprocess()\n",
    "        preprocess.load_state_dict(torch.load(path_preprocess), weights_only=True))\n",
    "    else:  # used the preprocess from load_tune_pth_model\n",
    "        preprocess = preprocess_tmp[0]\n",
    "\n",
    "    data = torch.zeros((1, 3, 224, 224))\n",
    "    # data = preprocess(data).cuda().half()\n",
    "    data = preprocess(data).to(device).eval().half()\n",
    "    \n",
    "    '''\n",
    "    if pth_model_name == 'inception_v3':\n",
    "        data = torch.zeros((1, 3, 299, 299)).cuda().half()   # inception_v3\n",
    "    else:\n",
    "        data = torch.zeros((1, 3, 224, 224)).cuda().half()  # resnet\n",
    "    '''    \n",
    "    model_trt = torch2trt(model, [data], fp16_mode=True)\n",
    "    \n",
    "    return model_trt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the optimized model using the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized model using the cell below\n",
    "@out.capture()\n",
    "def save_trt_model(pth_model_name, model_type, model_trt, path_trt_model):\n",
    "    import pandas as pd\n",
    "    print(\"saving built trt model  --\")\n",
    "    \n",
    "    # path_trt_model = os.path.join(dir_model_repo, 'road_following', \"best_steering_model_xy_trt_\"+pth_model_name+'.pth')\n",
    "    torch.save(model_trt.state_dict(), path_trt_model)\n",
    "\n",
    "    df_file = os.path.join(dir_model_repo, 'trt_model_tbl.csv')\n",
    "    if os.path.isfile(df_file):\n",
    "        df = pd.read_csv(df_file, header=None)\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # trt_model_path_tbl = os.path.join('.', 'road_following', \"best_steering_model_xy_trt_\"+pth_model_name+'.pth')\n",
    "    path_trt_model_preprocess = pth_ms.preprocess_path\n",
    "    df = df.append([[\"classifier\", model_type, path_trt_model, path_trt_model_preprocess]], ignore_index = False)\n",
    "    df = df.drop_duplicates()\n",
    "    df.to_csv(df_file, header=False, index=False)\n",
    "    return trt_model_path_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@out.capture()\n",
    "def start_trt_conversion(change):\n",
    "    button_OK.disabled=True\n",
    "    \n",
    "    all_model = True     # set True to convert all pytorch models\n",
    "    re_convert = False  # wether to do trt conversion of conerted trt model \n",
    "    \n",
    "    list_model_path = []\n",
    "    if not all_model:\n",
    "        list_model_path.append(model_path_widget.value)\n",
    "    else:\n",
    "        import pandas as pd\n",
    "        from jetbot.utils.model_selection import HEAD_LIST\n",
    "        df = pd.read_csv(os.path.join(dir_model_repo, \"torch_model_tbl.csv\"), header=None, names=HEAD_LIST) # load torch models list\n",
    "        mf = df[df.model_function == \"classifier\"]  # select all classifier models\n",
    "        for mp in mf.loc[:, ['model_path']].values.tolist():\n",
    "            list_model_path.append(os.path.join(dir_model_repo, mp[0].split('/', 1)[-1]))\n",
    "    # print(list_model_path)\n",
    "        \n",
    "    for model_path in list_model_path:\n",
    "        pth_model_name = model_path.split('/')[-1].split('.')[0].split('_', 4)[-1]\n",
    "        path_trt_model = os.path.join(dir_model_repo, 'road_following', \"best_steering_model_xy_trt_\"+pth_model_name+'.pth')\n",
    "        if os.path.isfile(path_trt_model) and not re_convert:\n",
    "            pass\n",
    "        else:\n",
    "            model_type, model, preprocess = load_trained_model(model_path, pth_model_name)\n",
    "            model_trt = trt_conversion(pth_model_name, model, preprocess)\n",
    "            save_trt_model(pth_model_name, model_type, model_trt, path_trt_model)\n",
    "            print(\"Building finished, and TRT model is saved in -- %s \\n\" % path_trt_model)\n",
    "        \n",
    "    button_OK.disabled=False\n",
    "    \n",
    "display(HBox([model_type_widget, model_path_widget]))\n",
    "\n",
    "button_OK = widgets.Button(description='OK', tooltip='Click to start', icon=\"start\")\n",
    "button_OK.style.button_color='lightblue'\n",
    "button_OK.on_click(start_trt_conversion)\n",
    "display(button_OK)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "Open live_demo_trt.ipynb to move JetBot with the TensorRT optimized model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
